{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(622, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"nback/result1.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3back', 1537.7, 796.38, 36.961999999999996, 4.696727272727268,\n",
       "       8.947000000000001, 16.387999999999998], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data = np.delete(data, 1, 1) \n",
    "    \n",
    "#data = np.delete(data, 1, 1) \n",
    "data = data[:,0:7]\n",
    "data.shape\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero: 206  one:  130  two:  139  three:  147\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == '0back'):\n",
    "        zero = zero + 1\n",
    "    if (data[i, 0] == '1back'):\n",
    "        one = one + 1\n",
    "    if (data[i, 0] == '2back'):\n",
    "        two = two + 1\n",
    "    if (data[i, 0] == '3back'):\n",
    "        three = three + 1\n",
    "\n",
    "print('zero:', zero, ' one: ', one, ' two: ', two, ' three: ', three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"0back\",\"1back\",\"2back\",\"3back\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])\n",
    "\n",
    "back0 = np.zeros((zero,6))\n",
    "back1 = np.zeros((one,6))\n",
    "back2 = np.zeros((two,6))\n",
    "back3 = np.zeros((three,6))\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == '0back'):\n",
    "        back0[j] = data[i, 1:]\n",
    "        j = j+1\n",
    "    if (data[i, 0] == '1back'):\n",
    "        back1[k] = data[i, 1:]\n",
    "        k = k+1\n",
    "    if (data[i, 0] == '2back'):\n",
    "        back2[l] = data[i, 1:]\n",
    "        l = l+1\n",
    "    if (data[i, 0] == '3back'):\n",
    "        back3[m] = data[i, 1:]\n",
    "        m = m+1\n",
    "\n",
    "y_data = data[:, 0]\n",
    "for i in range(len(data)):\n",
    "    y_data[i] = level2int[y_data[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data for convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track = 50\n",
    "null = np.array([0,0,0,0,0,0])\n",
    "\n",
    "for i in range(track-1):\n",
    "        back0 = np.vstack([back0, null])\n",
    "        back1 = np.vstack([back1, null])\n",
    "        back2 = np.vstack([back2, null])\n",
    "        back3 = np.vstack([back3, null])\n",
    "\n",
    "x_data = np.zeros((data.shape[0],6,track))         # final input data for the network\n",
    "y_one_hot = np.zeros((data.shape[0],4))          # to store one-hot data groupped\n",
    "\n",
    "for i in range(len(one_hot)):\n",
    "    y_one_hot[i]=one_hot[i]\n",
    "\n",
    "for i in range(len(back0)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back0[i+j]\n",
    "        \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1, len(back0)-track+1 + len(back1)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back1[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1 + len(back1)-track+1, len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back2[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1, \n",
    "                   len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1 + len(back3)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back3[index+j]\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 6, 50) (435, 4) (93, 6, 50) (93, 4) (94, 6, 50) (94, 4)\n"
     ]
    }
   ],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(input_shape=(x_train[0].shape[-2],x_train[0].shape[-1]),\n",
    "                        nb_filter=35,\n",
    "                        filter_length=5,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu')) \n",
    "\n",
    "model.add(MaxPooling1D(pool_length=2,stride=1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Convolution1D(nb_filter=30,\n",
    "                        filter_length=2,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 435 samples, validate on 93 samples\n",
      "Epoch 1/200\n",
      "435/435 [==============================] - 0s - loss: 1.3661 - acc: 0.3586 - val_loss: 1.3377 - val_acc: 0.4731\n",
      "Epoch 2/200\n",
      "435/435 [==============================] - 0s - loss: 1.2749 - acc: 0.5126 - val_loss: 1.2320 - val_acc: 0.4624\n",
      "Epoch 3/200\n",
      "435/435 [==============================] - 0s - loss: 1.1483 - acc: 0.5379 - val_loss: 1.0936 - val_acc: 0.5699\n",
      "Epoch 4/200\n",
      "435/435 [==============================] - 0s - loss: 1.0293 - acc: 0.6368 - val_loss: 0.9098 - val_acc: 0.7634\n",
      "Epoch 5/200\n",
      "435/435 [==============================] - 0s - loss: 0.8647 - acc: 0.7080 - val_loss: 0.7374 - val_acc: 0.7957\n",
      "Epoch 6/200\n",
      "435/435 [==============================] - 0s - loss: 0.7251 - acc: 0.7540 - val_loss: 0.5725 - val_acc: 0.8817\n",
      "Epoch 7/200\n",
      "435/435 [==============================] - 0s - loss: 0.6160 - acc: 0.8000 - val_loss: 0.4423 - val_acc: 0.9247\n",
      "Epoch 8/200\n",
      "435/435 [==============================] - 0s - loss: 0.5895 - acc: 0.7724 - val_loss: 0.3862 - val_acc: 0.9247\n",
      "Epoch 9/200\n",
      "435/435 [==============================] - 0s - loss: 0.5377 - acc: 0.8161 - val_loss: 0.3301 - val_acc: 0.9462\n",
      "Epoch 10/200\n",
      "435/435 [==============================] - 0s - loss: 0.4902 - acc: 0.8299 - val_loss: 0.2854 - val_acc: 0.9355\n",
      "Epoch 11/200\n",
      "435/435 [==============================] - 0s - loss: 0.4257 - acc: 0.8621 - val_loss: 0.2684 - val_acc: 0.9355\n",
      "Epoch 12/200\n",
      "435/435 [==============================] - 0s - loss: 0.4146 - acc: 0.8437 - val_loss: 0.2310 - val_acc: 0.9355\n",
      "Epoch 13/200\n",
      "435/435 [==============================] - 0s - loss: 0.3850 - acc: 0.8828 - val_loss: 0.2186 - val_acc: 0.9247\n",
      "Epoch 14/200\n",
      "435/435 [==============================] - 0s - loss: 0.3563 - acc: 0.8667 - val_loss: 0.1903 - val_acc: 0.9462\n",
      "Epoch 15/200\n",
      "435/435 [==============================] - 0s - loss: 0.3527 - acc: 0.8805 - val_loss: 0.1713 - val_acc: 0.9785\n",
      "Epoch 16/200\n",
      "435/435 [==============================] - 0s - loss: 0.3202 - acc: 0.8874 - val_loss: 0.1733 - val_acc: 0.9677\n",
      "Epoch 17/200\n",
      "435/435 [==============================] - 0s - loss: 0.3256 - acc: 0.8851 - val_loss: 0.1672 - val_acc: 0.9677\n",
      "Epoch 18/200\n",
      "435/435 [==============================] - 0s - loss: 0.3273 - acc: 0.8782 - val_loss: 0.1495 - val_acc: 0.9677\n",
      "Epoch 19/200\n",
      "435/435 [==============================] - 0s - loss: 0.2928 - acc: 0.8920 - val_loss: 0.1478 - val_acc: 0.9677\n",
      "Epoch 20/200\n",
      "435/435 [==============================] - 0s - loss: 0.3007 - acc: 0.8667 - val_loss: 0.1534 - val_acc: 0.9677\n",
      "Epoch 21/200\n",
      "435/435 [==============================] - 0s - loss: 0.3505 - acc: 0.8713 - val_loss: 0.1750 - val_acc: 0.9785\n",
      "Epoch 22/200\n",
      "435/435 [==============================] - 0s - loss: 0.2563 - acc: 0.9218 - val_loss: 0.1785 - val_acc: 0.9570\n",
      "Epoch 23/200\n",
      "435/435 [==============================] - 0s - loss: 0.2985 - acc: 0.8874 - val_loss: 0.1512 - val_acc: 0.9570\n",
      "Epoch 24/200\n",
      "435/435 [==============================] - 0s - loss: 0.2383 - acc: 0.9172 - val_loss: 0.1359 - val_acc: 0.9677\n",
      "Epoch 25/200\n",
      "435/435 [==============================] - 0s - loss: 0.2616 - acc: 0.8782 - val_loss: 0.1190 - val_acc: 0.9785\n",
      "Epoch 26/200\n",
      "435/435 [==============================] - 0s - loss: 0.2429 - acc: 0.9126 - val_loss: 0.1221 - val_acc: 0.9785\n",
      "Epoch 27/200\n",
      "435/435 [==============================] - 0s - loss: 0.2298 - acc: 0.9264 - val_loss: 0.1135 - val_acc: 0.9785\n",
      "Epoch 28/200\n",
      "435/435 [==============================] - 0s - loss: 0.2474 - acc: 0.8966 - val_loss: 0.1125 - val_acc: 0.9785\n",
      "Epoch 29/200\n",
      "435/435 [==============================] - 0s - loss: 0.2213 - acc: 0.9218 - val_loss: 0.1183 - val_acc: 0.9570\n",
      "Epoch 30/200\n",
      "435/435 [==============================] - 0s - loss: 0.2354 - acc: 0.9057 - val_loss: 0.1137 - val_acc: 0.9570\n",
      "Epoch 31/200\n",
      "435/435 [==============================] - 0s - loss: 0.2022 - acc: 0.9310 - val_loss: 0.1009 - val_acc: 0.9677\n",
      "Epoch 32/200\n",
      "435/435 [==============================] - 0s - loss: 0.2128 - acc: 0.9356 - val_loss: 0.1005 - val_acc: 0.9785\n",
      "Epoch 33/200\n",
      "435/435 [==============================] - 0s - loss: 0.2327 - acc: 0.9218 - val_loss: 0.1100 - val_acc: 0.9785\n",
      "Epoch 34/200\n",
      "435/435 [==============================] - 0s - loss: 0.2325 - acc: 0.9103 - val_loss: 0.0932 - val_acc: 0.9677\n",
      "Epoch 35/200\n",
      "435/435 [==============================] - 0s - loss: 0.2215 - acc: 0.9126 - val_loss: 0.0856 - val_acc: 0.9892\n",
      "Epoch 36/200\n",
      "435/435 [==============================] - 0s - loss: 0.1991 - acc: 0.9241 - val_loss: 0.0964 - val_acc: 0.9892\n",
      "Epoch 37/200\n",
      "435/435 [==============================] - 0s - loss: 0.1688 - acc: 0.9402 - val_loss: 0.0939 - val_acc: 0.9785\n",
      "Epoch 38/200\n",
      "435/435 [==============================] - 0s - loss: 0.1964 - acc: 0.9218 - val_loss: 0.0997 - val_acc: 0.9892\n",
      "Epoch 39/200\n",
      "435/435 [==============================] - 0s - loss: 0.1942 - acc: 0.9402 - val_loss: 0.1061 - val_acc: 0.9785\n",
      "Epoch 40/200\n",
      "435/435 [==============================] - 0s - loss: 0.1870 - acc: 0.9218 - val_loss: 0.0888 - val_acc: 0.9785\n",
      "Epoch 41/200\n",
      "435/435 [==============================] - 0s - loss: 0.1730 - acc: 0.9402 - val_loss: 0.1421 - val_acc: 0.9785\n",
      "Epoch 42/200\n",
      "435/435 [==============================] - 0s - loss: 0.2101 - acc: 0.9195 - val_loss: 0.1620 - val_acc: 0.9677\n",
      "Epoch 43/200\n",
      "435/435 [==============================] - 0s - loss: 0.1740 - acc: 0.9448 - val_loss: 0.1149 - val_acc: 0.9785\n",
      "Epoch 44/200\n",
      "435/435 [==============================] - 0s - loss: 0.1917 - acc: 0.9379 - val_loss: 0.0825 - val_acc: 0.9785\n",
      "Epoch 45/200\n",
      "435/435 [==============================] - 0s - loss: 0.1861 - acc: 0.9287 - val_loss: 0.0789 - val_acc: 0.9892\n",
      "Epoch 46/200\n",
      "435/435 [==============================] - 0s - loss: 0.1644 - acc: 0.9333 - val_loss: 0.0716 - val_acc: 0.9892\n",
      "Epoch 47/200\n",
      "435/435 [==============================] - 0s - loss: 0.1707 - acc: 0.9402 - val_loss: 0.0722 - val_acc: 0.9892\n",
      "Epoch 48/200\n",
      "435/435 [==============================] - 0s - loss: 0.1977 - acc: 0.9287 - val_loss: 0.0695 - val_acc: 0.9892\n",
      "Epoch 49/200\n",
      "435/435 [==============================] - 0s - loss: 0.1639 - acc: 0.9356 - val_loss: 0.0693 - val_acc: 0.9892\n",
      "Epoch 50/200\n",
      "435/435 [==============================] - 0s - loss: 0.1734 - acc: 0.9333 - val_loss: 0.0743 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "435/435 [==============================] - 0s - loss: 0.1466 - acc: 0.9471 - val_loss: 0.0724 - val_acc: 0.9892\n",
      "Epoch 52/200\n",
      "435/435 [==============================] - 0s - loss: 0.1492 - acc: 0.9540 - val_loss: 0.0894 - val_acc: 0.9785\n",
      "Epoch 53/200\n",
      "435/435 [==============================] - 0s - loss: 0.1558 - acc: 0.9379 - val_loss: 0.0888 - val_acc: 0.9785\n",
      "Epoch 54/200\n",
      "435/435 [==============================] - 0s - loss: 0.1550 - acc: 0.9425 - val_loss: 0.0960 - val_acc: 0.9785\n",
      "Epoch 55/200\n",
      "435/435 [==============================] - 0s - loss: 0.1289 - acc: 0.9540 - val_loss: 0.0893 - val_acc: 0.9785\n",
      "Epoch 56/200\n",
      "435/435 [==============================] - 0s - loss: 0.1471 - acc: 0.9517 - val_loss: 0.0762 - val_acc: 0.9785\n",
      "Epoch 57/200\n",
      "435/435 [==============================] - 0s - loss: 0.1514 - acc: 0.9517 - val_loss: 0.0790 - val_acc: 0.9892\n",
      "Epoch 58/200\n",
      "435/435 [==============================] - 0s - loss: 0.1472 - acc: 0.9379 - val_loss: 0.0812 - val_acc: 0.9892\n",
      "Epoch 59/200\n",
      "435/435 [==============================] - 0s - loss: 0.1361 - acc: 0.9471 - val_loss: 0.0841 - val_acc: 0.9677\n",
      "Epoch 60/200\n",
      "435/435 [==============================] - 0s - loss: 0.1361 - acc: 0.9517 - val_loss: 0.0866 - val_acc: 0.9785\n",
      "Epoch 61/200\n",
      "435/435 [==============================] - 0s - loss: 0.1504 - acc: 0.9448 - val_loss: 0.0718 - val_acc: 0.9785\n",
      "Epoch 62/200\n",
      "435/435 [==============================] - 0s - loss: 0.1580 - acc: 0.9448 - val_loss: 0.0604 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "435/435 [==============================] - 0s - loss: 0.1349 - acc: 0.9517 - val_loss: 0.0891 - val_acc: 0.9892\n",
      "Epoch 64/200\n",
      "435/435 [==============================] - 0s - loss: 0.1149 - acc: 0.9609 - val_loss: 0.1017 - val_acc: 0.9785\n",
      "Epoch 65/200\n",
      "435/435 [==============================] - 0s - loss: 0.1426 - acc: 0.9402 - val_loss: 0.1136 - val_acc: 0.9785\n",
      "Epoch 66/200\n",
      "435/435 [==============================] - 0s - loss: 0.1380 - acc: 0.9517 - val_loss: 0.1061 - val_acc: 0.9677\n",
      "Epoch 67/200\n",
      "435/435 [==============================] - 0s - loss: 0.1464 - acc: 0.9379 - val_loss: 0.0751 - val_acc: 0.9892\n",
      "Epoch 68/200\n",
      "435/435 [==============================] - 0s - loss: 0.1360 - acc: 0.9471 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "435/435 [==============================] - 0s - loss: 0.1463 - acc: 0.9448 - val_loss: 0.0634 - val_acc: 0.9892\n",
      "Epoch 70/200\n",
      "435/435 [==============================] - 0s - loss: 0.1445 - acc: 0.9425 - val_loss: 0.1037 - val_acc: 0.9892\n",
      "Epoch 71/200\n",
      "435/435 [==============================] - 0s - loss: 0.1321 - acc: 0.9448 - val_loss: 0.1276 - val_acc: 0.9785\n",
      "Epoch 72/200\n",
      "435/435 [==============================] - 0s - loss: 0.1453 - acc: 0.9448 - val_loss: 0.1356 - val_acc: 0.9677\n",
      "Epoch 73/200\n",
      "435/435 [==============================] - 0s - loss: 0.1489 - acc: 0.9448 - val_loss: 0.1260 - val_acc: 0.9677\n",
      "Epoch 74/200\n",
      "435/435 [==============================] - 0s - loss: 0.1291 - acc: 0.9471 - val_loss: 0.1052 - val_acc: 0.9677\n",
      "Epoch 75/200\n",
      "435/435 [==============================] - 0s - loss: 0.1044 - acc: 0.9678 - val_loss: 0.1110 - val_acc: 0.9677\n",
      "Epoch 76/200\n",
      "435/435 [==============================] - 0s - loss: 0.1117 - acc: 0.9655 - val_loss: 0.1077 - val_acc: 0.9677\n",
      "Epoch 77/200\n",
      "435/435 [==============================] - 0s - loss: 0.1460 - acc: 0.9471 - val_loss: 0.0849 - val_acc: 0.9785\n",
      "Epoch 78/200\n",
      "435/435 [==============================] - 0s - loss: 0.1342 - acc: 0.9402 - val_loss: 0.0780 - val_acc: 0.9785\n",
      "Epoch 79/200\n",
      "435/435 [==============================] - 0s - loss: 0.1034 - acc: 0.9724 - val_loss: 0.0777 - val_acc: 0.9785\n",
      "Epoch 80/200\n",
      "435/435 [==============================] - 0s - loss: 0.1017 - acc: 0.9632 - val_loss: 0.0978 - val_acc: 0.9677\n",
      "Epoch 81/200\n",
      "435/435 [==============================] - 0s - loss: 0.1362 - acc: 0.9448 - val_loss: 0.1107 - val_acc: 0.9677\n",
      "Epoch 82/200\n",
      "435/435 [==============================] - 0s - loss: 0.0969 - acc: 0.9678 - val_loss: 0.1154 - val_acc: 0.9677\n",
      "Epoch 83/200\n",
      "435/435 [==============================] - 0s - loss: 0.1088 - acc: 0.9632 - val_loss: 0.1248 - val_acc: 0.9570\n",
      "Epoch 84/200\n",
      "435/435 [==============================] - 0s - loss: 0.1319 - acc: 0.9517 - val_loss: 0.1113 - val_acc: 0.9677\n",
      "Epoch 85/200\n",
      "435/435 [==============================] - 0s - loss: 0.1392 - acc: 0.9517 - val_loss: 0.0861 - val_acc: 0.9570\n",
      "Epoch 86/200\n",
      "435/435 [==============================] - 0s - loss: 0.1102 - acc: 0.9586 - val_loss: 0.0726 - val_acc: 0.9570\n",
      "Epoch 87/200\n",
      "435/435 [==============================] - 0s - loss: 0.1131 - acc: 0.9448 - val_loss: 0.0847 - val_acc: 0.9677\n",
      "Epoch 88/200\n",
      "435/435 [==============================] - 0s - loss: 0.1047 - acc: 0.9609 - val_loss: 0.0934 - val_acc: 0.9677\n",
      "Epoch 89/200\n",
      "435/435 [==============================] - 0s - loss: 0.1037 - acc: 0.9563 - val_loss: 0.0865 - val_acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f28cf524a50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, nb_epoch=200, shuffle=True, callbacks=[earlyStopping], \n",
    "          validation_data = (x_valid, y_valid), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11948752514225372, 0.97872339664621555]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s     \n",
      "[3 0 3 2 0 1 0 2 1 0 0 1 1 0 3 3 3 1 0 2 2 2 2 0 2 0 2 0 0 3 1 0 2 0 0 1 0\n",
      " 2 3 0 3 0 0 0 2 3 3 1 3 1 2 2 2 1 0 0 1 0 2 0 3 0 1 0 3 2 0 0 0 0 2 0 3 2\n",
      " 2 3 2 3 2 0 3 0 3 2 0 2 2 2 2 0 1 3 3 1]\n",
      "32/94 [=========>....................] - ETA: 0s                precision    recall  f1-score   support\n",
      "\n",
      "class 0(0back)       0.94      1.00      0.97        32\n",
      "class 1(1back)       1.00      0.93      0.97        15\n",
      "class 2(2back)       1.00      1.00      1.00        26\n",
      " class3(3back)       1.00      0.95      0.98        21\n",
      "\n",
      "   avg / total       0.98      0.98      0.98        94\n",
      "\n",
      "[[32  0  0  0]\n",
      " [ 1 14  0  0]\n",
      " [ 0  0 26  0]\n",
      " [ 1  0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(0back)', 'class 1(1back)', 'class 2(2back)', 'class3(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"644pt\" viewBox=\"0.00 0.00 362.00 644.00\" width=\"362pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 640)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-640 358,-640 358,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139813253693968 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139813253693968</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-589 -0.5,-635 354.5,-635 354.5,-589 -0.5,-589\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-608.3\">convolution1d_input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-589 209.5,-635 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-619.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-612 264.5,-612 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-596.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"264.5,-589 264.5,-635 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-619.8\">(None, 6, 50)</text>\n",
       "<polyline fill=\"none\" points=\"264.5,-612 354.5,-612 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-596.8\">(None, 6, 50)</text>\n",
       "</g>\n",
       "<!-- 139813253694800 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139813253694800</title>\n",
       "<polygon fill=\"none\" points=\"4.5,-505 4.5,-551 349.5,-551 349.5,-505 4.5,-505\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-524.3\">convolution1d_1: Convolution1D</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-505 204.5,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-535.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-528 259.5,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-512.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-505 259.5,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-535.8\">(None, 6, 50)</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-528 349.5,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-512.8\">(None, 3, 35)</text>\n",
       "</g>\n",
       "<!-- 139813253693968&#45;&gt;139813253694800 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139813253693968-&gt;139813253694800</title>\n",
       "<path d=\"M177,-588.593C177,-580.118 177,-570.297 177,-561.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-561.096 177,-551.096 173.5,-561.096 180.5,-561.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139813253697360 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139813253697360</title>\n",
       "<polygon fill=\"none\" points=\"4.5,-421 4.5,-467 349.5,-467 349.5,-421 4.5,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-440.3\">maxpooling1d_1: MaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-421 204.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-444 259.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-421 259.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-451.8\">(None, 3, 35)</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-444 349.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-428.8\">(None, 2, 35)</text>\n",
       "</g>\n",
       "<!-- 139813253694800&#45;&gt;139813253697360 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139813253694800-&gt;139813253697360</title>\n",
       "<path d=\"M177,-504.593C177,-496.118 177,-486.297 177,-477.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-477.096 177,-467.096 173.5,-477.096 180.5,-477.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139813253136080 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139813253136080</title>\n",
       "<polygon fill=\"none\" points=\"42,-337 42,-383 312,-383 312,-337 42,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-356.3\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"167,-337 167,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-360 222,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-337 222,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-367.8\">(None, 2, 35)</text>\n",
       "<polyline fill=\"none\" points=\"222,-360 312,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-344.8\">(None, 2, 35)</text>\n",
       "</g>\n",
       "<!-- 139813253697360&#45;&gt;139813253136080 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139813253697360-&gt;139813253136080</title>\n",
       "<path d=\"M177,-420.593C177,-412.118 177,-402.297 177,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-393.096 177,-383.096 173.5,-393.096 180.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139813253506384 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139813253506384</title>\n",
       "<polygon fill=\"none\" points=\"4.5,-253 4.5,-299 349.5,-299 349.5,-253 4.5,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-272.3\">convolution1d_2: Convolution1D</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-253 204.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-276 259.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-253 259.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-283.8\">(None, 2, 35)</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-276 349.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-260.8\">(None, 1, 30)</text>\n",
       "</g>\n",
       "<!-- 139813253136080&#45;&gt;139813253506384 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139813253136080-&gt;139813253506384</title>\n",
       "<path d=\"M177,-336.593C177,-328.118 177,-318.297 177,-309.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-309.096 177,-299.096 173.5,-309.096 180.5,-309.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139813252965264 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139813252965264</title>\n",
       "<polygon fill=\"none\" points=\"42,-169 42,-215 312,-215 312,-169 42,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-188.3\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"167,-169 167,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-192 222,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-169 222,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-199.8\">(None, 1, 30)</text>\n",
       "<polyline fill=\"none\" points=\"222,-192 312,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-176.8\">(None, 1, 30)</text>\n",
       "</g>\n",
       "<!-- 139813253506384&#45;&gt;139813252965264 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139813253506384-&gt;139813252965264</title>\n",
       "<path d=\"M177,-252.593C177,-244.118 177,-234.297 177,-225.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-225.096 177,-215.096 173.5,-225.096 180.5,-225.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139813252884112 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139813252884112</title>\n",
       "<polygon fill=\"none\" points=\"49.5,-85 49.5,-131 304.5,-131 304.5,-85 49.5,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-104.3\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-85 159.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-108 214.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"214.5,-85 214.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-115.8\">(None, 1, 30)</text>\n",
       "<polyline fill=\"none\" points=\"214.5,-108 304.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-92.8\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 139813252965264&#45;&gt;139813252884112 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139813252965264-&gt;139813252884112</title>\n",
       "<path d=\"M177,-168.593C177,-160.118 177,-150.297 177,-141.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-141.096 177,-131.096 173.5,-141.096 180.5,-141.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139813252247312 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139813252247312</title>\n",
       "<polygon fill=\"none\" points=\"60.5,-1 60.5,-47 293.5,-47 293.5,-1 60.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"111.5\" y=\"-20.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"162.5,-1 162.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"162.5,-24 217.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-1 217.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-31.8\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-24 293.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-8.8\">(None, 4)</text>\n",
       "</g>\n",
       "<!-- 139813252884112&#45;&gt;139813252247312 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139813252884112-&gt;139813252247312</title>\n",
       "<path d=\"M177,-84.5931C177,-76.1177 177,-66.2974 177,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-57.0958 177,-47.0959 173.5,-57.0959 180.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)\n",
    "\n",
    "# Save the model as png file\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model_cnn.png', show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
