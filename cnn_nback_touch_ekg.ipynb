{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(313, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"result9.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "touch_only = 'false'\n",
    "touch_heart = 'false'\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete irrelevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " one:  98  two:  104  three:  111\n"
     ]
    }
   ],
   "source": [
    "data = np.delete(data, 13, 1)    \n",
    "data = np.delete(data, 12, 1)  \n",
    "data = np.delete(data, 11, 1)    \n",
    "data = np.delete(data, 4, 1)     \n",
    "data = np.delete(data, 3, 1)   \n",
    "data = np.delete(data, 2, 1) \n",
    "data = np.delete(data, 1, 1)\n",
    "data.shape\n",
    "\n",
    "if(touch_only == 'true'):\n",
    "    data = np.delete(data, 7, 1)    \n",
    "    data = np.delete(data, 3, 1)    \n",
    "    data = np.delete(data, 2, 1)     \n",
    "\n",
    "if(touch_heart == 'true'):\n",
    "    data = np.delete(data, 7, 1)     \n",
    "    \n",
    "data.shape\n",
    "\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == 'NbackSym1'):\n",
    "        one = one + 1\n",
    "    if (data[i, 0] == 'NbackSym2'):\n",
    "        two = two + 1\n",
    "    if (data[i, 0] == 'NbackSym3'):\n",
    "        three = three + 1\n",
    "\n",
    "print(' one: ', one, ' two: ', two, ' three: ', three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"NbackSym1\",\"NbackSym2\",\"NbackSym3\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,data.shape[1]):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])\n",
    "\n",
    "back1 = np.zeros((one,data.shape[1]-1))\n",
    "back2 = np.zeros((two,data.shape[1]-1))\n",
    "back3 = np.zeros((three,data.shape[1]-1))\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == 'NbackSym1'):\n",
    "        back1[j] = data[i, 1:]\n",
    "        j = j+1\n",
    "    if (data[i, 0] == 'NbackSym2'):\n",
    "        back2[k] = data[i, 1:]\n",
    "        k = k+1\n",
    "    if (data[i, 0] == 'NbackSym3'):\n",
    "        back3[l] = data[i, 1:]\n",
    "        l = l+1\n",
    "\n",
    "y_data = data[:, 0]\n",
    "for i in range(len(data)):\n",
    "    y_data[i] = level2int[y_data[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data for convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track = 20\n",
    "null = np.array([0,0,0,0,0,0,0])\n",
    "\n",
    "for i in range(track-1):\n",
    "        back1 = np.vstack([back1, null])\n",
    "        back2 = np.vstack([back2, null])\n",
    "        back3 = np.vstack([back3, null])\n",
    "\n",
    "x_data = np.zeros((data.shape[0],back1.shape[1],track))         # final input data for the network\n",
    "y_one_hot = np.zeros((data.shape[0],one_hot.shape[1]))          # to store one-hot data groupped\n",
    "\n",
    "for i in range(len(one_hot)):\n",
    "    y_one_hot[i]=one_hot[i]\n",
    "\n",
    "for i in range(len(back1)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back1[i+j]\n",
    "        \n",
    "index = 0\n",
    "for i in range(len(back1)-track+1, len(back1)-track+1 + len(back2)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back2[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back1)-track+1 + len(back2)-track+1, len(back1)-track+1 + len(back2)-track+1 + len(back3)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back3[index+j]\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 7, 20) (219, 3) (46, 7, 20) (46, 3) (48, 7, 20) (48, 3)\n"
     ]
    }
   ],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(input_shape=(x_train[0].shape[-2],x_train[0].shape[-1]),\n",
    "                        nb_filter=35,\n",
    "                        filter_length=4,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu')) \n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=30,\n",
    "                        filter_length=2,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219 samples, validate on 46 samples\n",
      "Epoch 1/200\n",
      "219/219 [==============================] - 0s - loss: 1.0850 - acc: 0.3927 - val_loss: 1.0663 - val_acc: 0.6957\n",
      "Epoch 2/200\n",
      "219/219 [==============================] - 0s - loss: 1.0513 - acc: 0.6621 - val_loss: 1.0179 - val_acc: 0.7609\n",
      "Epoch 3/200\n",
      "219/219 [==============================] - 0s - loss: 0.9951 - acc: 0.7306 - val_loss: 0.9456 - val_acc: 0.7826\n",
      "Epoch 4/200\n",
      "219/219 [==============================] - 0s - loss: 0.9239 - acc: 0.7215 - val_loss: 0.8483 - val_acc: 0.7609\n",
      "Epoch 5/200\n",
      "219/219 [==============================] - 0s - loss: 0.8396 - acc: 0.8128 - val_loss: 0.7366 - val_acc: 0.7826\n",
      "Epoch 6/200\n",
      "219/219 [==============================] - 0s - loss: 0.7060 - acc: 0.8539 - val_loss: 0.6210 - val_acc: 0.8478\n",
      "Epoch 7/200\n",
      "219/219 [==============================] - 0s - loss: 0.6100 - acc: 0.8539 - val_loss: 0.5128 - val_acc: 0.8913\n",
      "Epoch 8/200\n",
      "219/219 [==============================] - 0s - loss: 0.5325 - acc: 0.8493 - val_loss: 0.4208 - val_acc: 0.8913\n",
      "Epoch 9/200\n",
      "219/219 [==============================] - 0s - loss: 0.4416 - acc: 0.8630 - val_loss: 0.3488 - val_acc: 0.9130\n",
      "Epoch 10/200\n",
      "219/219 [==============================] - 0s - loss: 0.3901 - acc: 0.8721 - val_loss: 0.2965 - val_acc: 0.9348\n",
      "Epoch 11/200\n",
      "219/219 [==============================] - 0s - loss: 0.3284 - acc: 0.9269 - val_loss: 0.2578 - val_acc: 0.9348\n",
      "Epoch 12/200\n",
      "219/219 [==============================] - 0s - loss: 0.2879 - acc: 0.9315 - val_loss: 0.2224 - val_acc: 0.9565\n",
      "Epoch 13/200\n",
      "219/219 [==============================] - 0s - loss: 0.2485 - acc: 0.9361 - val_loss: 0.1926 - val_acc: 0.9348\n",
      "Epoch 14/200\n",
      "219/219 [==============================] - 0s - loss: 0.2338 - acc: 0.9224 - val_loss: 0.1725 - val_acc: 0.9565\n",
      "Epoch 15/200\n",
      "219/219 [==============================] - 0s - loss: 0.2151 - acc: 0.9224 - val_loss: 0.1567 - val_acc: 0.9783\n",
      "Epoch 16/200\n",
      "219/219 [==============================] - 0s - loss: 0.2158 - acc: 0.9452 - val_loss: 0.1470 - val_acc: 0.9783\n",
      "Epoch 17/200\n",
      "219/219 [==============================] - 0s - loss: 0.1832 - acc: 0.9543 - val_loss: 0.1348 - val_acc: 0.9783\n",
      "Epoch 18/200\n",
      "219/219 [==============================] - 0s - loss: 0.1770 - acc: 0.9589 - val_loss: 0.1216 - val_acc: 0.9783\n",
      "Epoch 19/200\n",
      "219/219 [==============================] - 0s - loss: 0.1793 - acc: 0.9224 - val_loss: 0.1121 - val_acc: 0.9783\n",
      "Epoch 20/200\n",
      "219/219 [==============================] - 0s - loss: 0.1549 - acc: 0.9726 - val_loss: 0.1069 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "219/219 [==============================] - 0s - loss: 0.1693 - acc: 0.9498 - val_loss: 0.0993 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "219/219 [==============================] - 0s - loss: 0.1084 - acc: 0.9863 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "219/219 [==============================] - 0s - loss: 0.1298 - acc: 0.9635 - val_loss: 0.0858 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "219/219 [==============================] - 0s - loss: 0.1056 - acc: 0.9726 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "219/219 [==============================] - 0s - loss: 0.0939 - acc: 0.9772 - val_loss: 0.0740 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "219/219 [==============================] - 0s - loss: 0.1109 - acc: 0.9680 - val_loss: 0.0696 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "219/219 [==============================] - 0s - loss: 0.1121 - acc: 0.9772 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "219/219 [==============================] - 0s - loss: 0.0861 - acc: 0.9772 - val_loss: 0.0648 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "219/219 [==============================] - 0s - loss: 0.0940 - acc: 0.9863 - val_loss: 0.0602 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "219/219 [==============================] - 0s - loss: 0.1108 - acc: 0.9726 - val_loss: 0.0579 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "219/219 [==============================] - 0s - loss: 0.0769 - acc: 0.9817 - val_loss: 0.0572 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "219/219 [==============================] - 0s - loss: 0.0971 - acc: 0.9726 - val_loss: 0.0546 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "219/219 [==============================] - 0s - loss: 0.0999 - acc: 0.9772 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "219/219 [==============================] - 0s - loss: 0.0804 - acc: 0.9817 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "219/219 [==============================] - 0s - loss: 0.0955 - acc: 0.9680 - val_loss: 0.0415 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "219/219 [==============================] - 0s - loss: 0.0584 - acc: 0.9909 - val_loss: 0.0384 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "219/219 [==============================] - 0s - loss: 0.0627 - acc: 0.9954 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "219/219 [==============================] - 0s - loss: 0.0768 - acc: 0.9772 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "219/219 [==============================] - 0s - loss: 0.0798 - acc: 0.9817 - val_loss: 0.0335 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "219/219 [==============================] - 0s - loss: 0.0600 - acc: 0.9863 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "219/219 [==============================] - 0s - loss: 0.0789 - acc: 0.9772 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "219/219 [==============================] - 0s - loss: 0.0513 - acc: 0.9909 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "219/219 [==============================] - 0s - loss: 0.0639 - acc: 0.9817 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "219/219 [==============================] - 0s - loss: 0.0704 - acc: 0.9772 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "219/219 [==============================] - 0s - loss: 0.0697 - acc: 0.9817 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "219/219 [==============================] - 0s - loss: 0.0773 - acc: 0.9635 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "219/219 [==============================] - 0s - loss: 0.0519 - acc: 0.9909 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "219/219 [==============================] - 0s - loss: 0.0413 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "219/219 [==============================] - 0s - loss: 0.0515 - acc: 0.9863 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "219/219 [==============================] - 0s - loss: 0.0685 - acc: 0.9772 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "219/219 [==============================] - 0s - loss: 0.0431 - acc: 0.9909 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "219/219 [==============================] - 0s - loss: 0.0494 - acc: 0.9909 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "219/219 [==============================] - 0s - loss: 0.0495 - acc: 0.9817 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "219/219 [==============================] - 0s - loss: 0.0372 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "219/219 [==============================] - 0s - loss: 0.0473 - acc: 0.9954 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "219/219 [==============================] - 0s - loss: 0.0520 - acc: 0.9863 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "219/219 [==============================] - 0s - loss: 0.0377 - acc: 0.9954 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "219/219 [==============================] - 0s - loss: 0.0490 - acc: 0.9863 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "219/219 [==============================] - 0s - loss: 0.0394 - acc: 0.9909 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "219/219 [==============================] - 0s - loss: 0.0477 - acc: 0.9863 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "219/219 [==============================] - 0s - loss: 0.0406 - acc: 0.9909 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "219/219 [==============================] - 0s - loss: 0.0396 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "219/219 [==============================] - 0s - loss: 0.0292 - acc: 0.9954 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "219/219 [==============================] - 0s - loss: 0.0508 - acc: 0.9863 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "219/219 [==============================] - 0s - loss: 0.0308 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "219/219 [==============================] - 0s - loss: 0.0338 - acc: 0.9909 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "219/219 [==============================] - 0s - loss: 0.0410 - acc: 0.9909 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "219/219 [==============================] - 0s - loss: 0.0274 - acc: 0.9954 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "219/219 [==============================] - 0s - loss: 0.0377 - acc: 0.9954 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "219/219 [==============================] - 0s - loss: 0.0470 - acc: 0.9817 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "219/219 [==============================] - 0s - loss: 0.0366 - acc: 0.9863 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "219/219 [==============================] - 0s - loss: 0.0320 - acc: 0.9954 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "219/219 [==============================] - 0s - loss: 0.0322 - acc: 0.9909 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "219/219 [==============================] - 0s - loss: 0.0346 - acc: 0.9909 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "219/219 [==============================] - 0s - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "219/219 [==============================] - 0s - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "219/219 [==============================] - 0s - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "219/219 [==============================] - 0s - loss: 0.0211 - acc: 0.9954 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "219/219 [==============================] - 0s - loss: 0.0363 - acc: 0.9909 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "219/219 [==============================] - 0s - loss: 0.0659 - acc: 0.9863 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "219/219 [==============================] - 0s - loss: 0.0310 - acc: 0.9909 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "219/219 [==============================] - 0s - loss: 0.0304 - acc: 0.9863 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "219/219 [==============================] - 0s - loss: 0.0265 - acc: 0.9909 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "219/219 [==============================] - 0s - loss: 0.0256 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "219/219 [==============================] - 0s - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "219/219 [==============================] - 0s - loss: 0.0316 - acc: 0.9909 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "219/219 [==============================] - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "219/219 [==============================] - 0s - loss: 0.0301 - acc: 0.9863 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "219/219 [==============================] - 0s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "219/219 [==============================] - 0s - loss: 0.0235 - acc: 0.9954 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "219/219 [==============================] - 0s - loss: 0.0264 - acc: 0.9909 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "219/219 [==============================] - 0s - loss: 0.0276 - acc: 0.9954 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "219/219 [==============================] - 0s - loss: 0.0242 - acc: 0.9954 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "219/219 [==============================] - 0s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "219/219 [==============================] - 0s - loss: 0.0269 - acc: 0.9909 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "219/219 [==============================] - 0s - loss: 0.0256 - acc: 0.9909 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "219/219 [==============================] - 0s - loss: 0.0319 - acc: 0.9954 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "219/219 [==============================] - 0s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "219/219 [==============================] - 0s - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "219/219 [==============================] - 0s - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "219/219 [==============================] - 0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "219/219 [==============================] - 0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "219/219 [==============================] - 0s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "219/219 [==============================] - 0s - loss: 0.0355 - acc: 0.9863 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "219/219 [==============================] - 0s - loss: 0.0205 - acc: 0.9954 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "219/219 [==============================] - 0s - loss: 0.0176 - acc: 0.9954 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "219/219 [==============================] - 0s - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "219/219 [==============================] - 0s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "219/219 [==============================] - 0s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "219/219 [==============================] - 0s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "219/219 [==============================] - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "219/219 [==============================] - 0s - loss: 0.0214 - acc: 0.9954 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "219/219 [==============================] - 0s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "219/219 [==============================] - 0s - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "219/219 [==============================] - 0s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "219/219 [==============================] - 0s - loss: 0.0195 - acc: 0.9909 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "219/219 [==============================] - 0s - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "219/219 [==============================] - 0s - loss: 0.0311 - acc: 0.9954 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "219/219 [==============================] - 0s - loss: 0.0168 - acc: 0.9954 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "219/219 [==============================] - 0s - loss: 0.0217 - acc: 0.9954 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "219/219 [==============================] - 0s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "219/219 [==============================] - 0s - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "219/219 [==============================] - 0s - loss: 0.0212 - acc: 0.9909 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "219/219 [==============================] - 0s - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "219/219 [==============================] - 0s - loss: 0.0149 - acc: 0.9954 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "219/219 [==============================] - 0s - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "219/219 [==============================] - 0s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "219/219 [==============================] - 0s - loss: 0.0192 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "219/219 [==============================] - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "219/219 [==============================] - 0s - loss: 0.0277 - acc: 0.9909 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "219/219 [==============================] - 0s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "219/219 [==============================] - 0s - loss: 0.0207 - acc: 0.9909 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "219/219 [==============================] - 0s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "219/219 [==============================] - 0s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "219/219 [==============================] - 0s - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "219/219 [==============================] - 0s - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "219/219 [==============================] - 0s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "219/219 [==============================] - 0s - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "219/219 [==============================] - 0s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "219/219 [==============================] - 0s - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "219/219 [==============================] - 0s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "219/219 [==============================] - 0s - loss: 0.0156 - acc: 0.9954 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "219/219 [==============================] - 0s - loss: 0.0221 - acc: 0.9954 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "219/219 [==============================] - 0s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "219/219 [==============================] - 0s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "219/219 [==============================] - 0s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "219/219 [==============================] - 0s - loss: 0.0169 - acc: 0.9954 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "219/219 [==============================] - 0s - loss: 0.0303 - acc: 0.9909 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "219/219 [==============================] - 0s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "219/219 [==============================] - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "219/219 [==============================] - 0s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "219/219 [==============================] - 0s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "219/219 [==============================] - 0s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "219/219 [==============================] - 0s - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "219/219 [==============================] - 0s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "219/219 [==============================] - 0s - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "219/219 [==============================] - 0s - loss: 0.0186 - acc: 0.9954 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "219/219 [==============================] - 0s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "219/219 [==============================] - 0s - loss: 0.0199 - acc: 0.9954 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "219/219 [==============================] - 0s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "219/219 [==============================] - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "219/219 [==============================] - 0s - loss: 0.0124 - acc: 0.9954 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "219/219 [==============================] - 0s - loss: 0.0117 - acc: 0.9954 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "219/219 [==============================] - 0s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "219/219 [==============================] - 0s - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "219/219 [==============================] - 0s - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "219/219 [==============================] - 0s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "219/219 [==============================] - 0s - loss: 0.0119 - acc: 0.9954 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "219/219 [==============================] - 0s - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "219/219 [==============================] - 0s - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "219/219 [==============================] - 0s - loss: 0.0156 - acc: 0.9954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "219/219 [==============================] - 0s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "219/219 [==============================] - 0s - loss: 0.0115 - acc: 0.9954 - val_loss: 0.0032 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91cc1fcb50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, nb_epoch=200, shuffle=True, callbacks=[earlyStopping], \n",
    "          validation_data = (x_valid, y_valid), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0041245096363127232, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/48 [===================>..........] - ETA: 0s[0 2 2 1 2 1 2 2 2 1 2 2 0 2 2 2 2 1 1 1 0 0 2 0 1 0 2 1 2 0 2 1 0 2 0 2 1\n",
      " 1 0 2 0 0 0 2 1 2 1 1]\n",
      "32/48 [===================>..........] - ETA: 0s                precision    recall  f1-score   support\n",
      "\n",
      "class 0(0back)       1.00      1.00      1.00        13\n",
      "class 1(1back)       1.00      1.00      1.00        14\n",
      "class 2(2back)       1.00      1.00      1.00        21\n",
      "\n",
      "   avg / total       1.00      1.00      1.00        48\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(0back)', 'class 1(1back)', 'class 2(2back)', 'class3(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"560pt\" viewBox=\"0.00 0.00 362.00 560.00\" width=\"362pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 556)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-556 358,-556 358,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140264178053840 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140264178053840</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-505 -0.5,-551 354.5,-551 354.5,-505 -0.5,-505\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-524.3\">convolution1d_input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-505 209.5,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-535.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-528 264.5,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-512.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"264.5,-505 264.5,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-535.8\">(None, 7, 20)</text>\n",
       "<polyline fill=\"none\" points=\"264.5,-528 354.5,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-512.8\">(None, 7, 20)</text>\n",
       "</g>\n",
       "<!-- 140264178053456 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140264178053456</title>\n",
       "<polygon fill=\"none\" points=\"4.5,-421 4.5,-467 349.5,-467 349.5,-421 4.5,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-440.3\">convolution1d_1: Convolution1D</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-421 204.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-444 259.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-421 259.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-451.8\">(None, 7, 20)</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-444 349.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-428.8\">(None, 4, 35)</text>\n",
       "</g>\n",
       "<!-- 140264178053840&#45;&gt;140264178053456 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140264178053840-&gt;140264178053456</title>\n",
       "<path d=\"M177,-504.593C177,-496.118 177,-486.297 177,-477.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-477.096 177,-467.096 173.5,-477.096 180.5,-477.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140264178053584 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140264178053584</title>\n",
       "<polygon fill=\"none\" points=\"42,-337 42,-383 312,-383 312,-337 42,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-356.3\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"167,-337 167,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-360 222,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-337 222,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-367.8\">(None, 4, 35)</text>\n",
       "<polyline fill=\"none\" points=\"222,-360 312,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-344.8\">(None, 4, 35)</text>\n",
       "</g>\n",
       "<!-- 140264178053456&#45;&gt;140264178053584 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140264178053456-&gt;140264178053584</title>\n",
       "<path d=\"M177,-420.593C177,-412.118 177,-402.297 177,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-393.096 177,-383.096 173.5,-393.096 180.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140264178054544 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140264178054544</title>\n",
       "<polygon fill=\"none\" points=\"4.5,-253 4.5,-299 349.5,-299 349.5,-253 4.5,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-272.3\">convolution1d_2: Convolution1D</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-253 204.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-276 259.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-253 259.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-283.8\">(None, 4, 35)</text>\n",
       "<polyline fill=\"none\" points=\"259.5,-276 349.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-260.8\">(None, 2, 30)</text>\n",
       "</g>\n",
       "<!-- 140264178053584&#45;&gt;140264178054544 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140264178053584-&gt;140264178054544</title>\n",
       "<path d=\"M177,-336.593C177,-328.118 177,-318.297 177,-309.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-309.096 177,-299.096 173.5,-309.096 180.5,-309.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140264177226832 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140264177226832</title>\n",
       "<polygon fill=\"none\" points=\"42,-169 42,-215 312,-215 312,-169 42,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-188.3\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"167,-169 167,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-192 222,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-169 222,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-199.8\">(None, 2, 30)</text>\n",
       "<polyline fill=\"none\" points=\"222,-192 312,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-176.8\">(None, 2, 30)</text>\n",
       "</g>\n",
       "<!-- 140264178054544&#45;&gt;140264177226832 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140264178054544-&gt;140264177226832</title>\n",
       "<path d=\"M177,-252.593C177,-244.118 177,-234.297 177,-225.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-225.096 177,-215.096 173.5,-225.096 180.5,-225.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140264177229776 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140264177229776</title>\n",
       "<polygon fill=\"none\" points=\"49.5,-85 49.5,-131 304.5,-131 304.5,-85 49.5,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-104.3\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-85 159.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-108 214.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"214.5,-85 214.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-115.8\">(None, 2, 30)</text>\n",
       "<polyline fill=\"none\" points=\"214.5,-108 304.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-92.8\">(None, 60)</text>\n",
       "</g>\n",
       "<!-- 140264177226832&#45;&gt;140264177229776 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140264177226832-&gt;140264177229776</title>\n",
       "<path d=\"M177,-168.593C177,-160.118 177,-150.297 177,-141.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-141.096 177,-131.096 173.5,-141.096 180.5,-141.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140264177035792 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140264177035792</title>\n",
       "<polygon fill=\"none\" points=\"60.5,-1 60.5,-47 293.5,-47 293.5,-1 60.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"111.5\" y=\"-20.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"162.5,-1 162.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"162.5,-24 217.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-1 217.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-31.8\">(None, 60)</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-24 293.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-8.8\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 140264177229776&#45;&gt;140264177035792 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140264177229776-&gt;140264177035792</title>\n",
       "<path d=\"M177,-84.5931C177,-76.1177 177,-66.2974 177,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"180.5,-57.0958 177,-47.0959 173.5,-57.0959 180.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)\n",
    "\n",
    "# Save the model as png file\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model_cnn.png', show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
